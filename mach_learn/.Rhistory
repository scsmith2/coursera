print("This is Scott Smith")
install.packages("htmltools")
install.packages("caTools")
install.packages("rmarkdown")
clear
home
library(caret); library(ggplot2)
# Download test & training csv's
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv")
#Load test data into 'testdata'
td <- read.csv("pml-training.csv",as.is=TRUE)
#Clean up data
names(td)[names(td)=="kurtosis_picth_belt"]<-"kurtosis_pitch_belt"
#Remove columns that are >10% NA
l <- length(td$classe)
td <- td[,colSums(!is.na(td))>(.9*l)]
#Remove columns that are not features
drops <- c("X",
"user_name",
"raw_timestamp_part_1",
"raw_timestamp_part_2",
"cvtd_timestamp",
"new_window",
"num_window")
td <- td[,!(names(td) %in% drops)]
featurePlot(x = td[,1:10],
y = td$classe,
plot = "pairs")
setwd("~/coursera/mach_learn")
library(caret); library(ggplot2)
# Download test & training csv's
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv")
#Load test data into 'testdata'
td <- read.csv("pml-training.csv",as.is=TRUE)
#Clean up data
names(td)[names(td)=="kurtosis_picth_belt"]<-"kurtosis_pitch_belt"
#Remove columns that are >10% NA
l <- length(td$classe)
td <- td[,colSums(!is.na(td))>(.9*l)]
#Remove columns that are not features
drops <- c("X",
"user_name",
"raw_timestamp_part_1",
"raw_timestamp_part_2",
"cvtd_timestamp",
"new_window",
"num_window")
td <- td[,!(names(td) %in% drops)]
featurePlot(x = td[,1:10],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,2:16],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,1],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,17:21],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,17:21],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,22:30],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,31:36],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,37:43],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,44:50],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,51:58],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,54:62],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,63:70],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,71:78],
y = td$classe,
plot = "pairs")
featurePlot(x = td[,79:86],
y = td$classe,
plot = "pairs")
plot(td$accel_forearm_z,td$magnet_forearm_z)
plot(td$accel_forearm_z,td$magnet_forearm_z,colour=td$classe)
ggplot(td$accel_forearm_z,td$magnet_forearm_z,colour=td$classe)
qplot(td$accel_forearm_z,td$magnet_forearm_z,colour=td$classe)
qplot(td$total_accel_belt,td$magnet_forearm_z,colour=td$classe)
qplot(td$total_accel_belt,td$gyros_belt_x,colour=td$classe)
qplot(td$roll_forearm,td$yaw_forearm,colour=td$classe)
params <-c(td$pitch_belt,
td$yaw_belt,
td$total_accel_belt,
td$total_accel_arm,
td$total_accel_dumbbell,
td$roll_forearm,
td$yaw_forearm)
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE)
params <-(td$pitch_belt,
td$yaw_belt,
td$total_accel_belt,
td$total_accel_arm,
td$total_accel_dumbbell,
td$roll_forearm,
td$yaw_forearm)
dat <- cbind(td$pitch_belt,td$yaw_belt)
dat <- data.frame(td$pitch_belt,td$yaw_belt)
dat <- data.frame(td$classe,
td$pitch_belt,
td$yaw_belt,
td$total_accel_belt,
td$total_accel_arm,
td$total_accel_dumbbell,
td$roll_forearm,
td$yaw_forearm)
dat <- data.frame(td$classe,
td$pitch_belt,
td$yaw_belt,
td$total_accel_belt,
td$total_accel_arm,
td$total_accel_dumbbell,
td$roll_forearm,
td$yaw_forearm)
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE)
ldaFit <- train(classe ~ params,
data = dat,
method = "lda",
trControl = ctrl,
metric = "Accuracy")
ldaFit <- train(td.classe ~ .,
data = dat,
method = "lda",
trControl = ctrl,
metric = "Accuracy")
summary(ldaFit)
confusionPlot(ldaFit,training)
confusionMatrix(ldaFit,training)
ldaClasses <- predict(ldaFit,newdata=training)
ldaClasses <- predict(ldaFit,newdata=td)
ldaClasses <- predict(ldaFit,newdata=dat)
confusionMatrix(ldaClasses,dat$td.classes)
summary(ldaClasses
)
summary(dat$td.classe)
confusionMatrix(ldaClasses,dat$td.classe)
ldaFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "Accuracy")
ctrl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 10,
classProbs = TRUE)
ldaFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "Accuracy")
ctrl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 10,
classProbs = TRUE)
ldaFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "best")
ctrl <- trainControl(method = "cv",
number = 5,
repeats = 10,
classProbs = TRUE)
ldaFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "best")
ctrl <- trainControl(method = "cv",
summaryFunction = twoClassSummary,
#                     number = 5,
#                     repeats = 10,
classProbs = TRUE)
gbmFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "ROC")
ctrl <- trainControl(method = "cv",
#                     number = 5,
#                     repeats = 10,
classProbs = TRUE)
gbmFit <- train(td.classe ~ .,
data = dat,
method = "gbm",
trControl = ctrl,
metric = "ROC")
ctrl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 10,
classProbs = TRUE)
ldaFit <- train(td$classe ~ .,
data = td,
method = "lda",
trControl = ctrl,
metric = "ROC")
model <- NaiveBayes(td.classe ~ ., data=dat)
model <- train(td.classe ~ .,
data = dat,
method="NaiveBayes")
model <- train(td.classe ~ .,
data = dat,
method="nb")
install.package("klaR")
install.packages("klaR")
install.packages("klaR")
library(caret); library(ggplot2)
# Download test & training csv's
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv")
#Load test data into 'testdata'
td <- read.csv("pml-training.csv",as.is=TRUE)
#Clean up data
names(td)[names(td)=="kurtosis_picth_belt"]<-"kurtosis_pitch_belt"
#Remove columns that are >10% NA
l <- length(td$classe)
td <- td[,colSums(!is.na(td))>(.9*l)]
#Remove columns that are not features
drops <- c("X",
"user_name",
"raw_timestamp_part_1",
"raw_timestamp_part_2",
"cvtd_timestamp",
"new_window",
"num_window")
td <- td[,!(names(td) %in% drops)]
#featurePlot(x = td[,79:86],
y = td$classe,
plot = "pairs")
#qplot(td$roll_forearm,td$yaw_forearm,colour=td$classe)
#Convert character features to numeric
#w <- which(sapply(td,class) == 'character')
#td[w] <- lapply(td[w], function(x) as.numeric(x))
dat <- data.frame(td$classe,
td$pitch_belt,
td$yaw_belt,
td$total_accel_belt,
td$total_accel_arm,
td$total_accel_dumbbell,
td$roll_forearm,
td$yaw_forearm)
nbFit <- train(td.classe ~ .,
data = dat,
method="nb")
