setwd("C:/users/scott_admin/documents/git_repo/coursera/mach_learn")
library(ElemStatLearn); data(prostate)
str(prostate)
small=prostate[1:5,]
lm(lpsa ~ ., data = small) #Fit linear model
library(ISLR); data(Wage);
library(ggplot2); library(caret)
Wage <- subset(Wage, select = -c(logwage))
inBuild <- createDataPartition(y = Wage$wage,
p = .7, list = FALSE)
validation <- Wage[-inBuild,]
buildData <- Wage[inBuild,]
inTrain <- createDataPartition(y = buildData$wage,
p = .7, list = FALSE)
training <- buildData[inTrain,]
testing <- buildData[-inTrain,]
dim(training); dim(testing); dim(validation)
mod1 <- train(wage ~ .,
method = "glm",
data = training)
mod2 <- train(wage ~ .,
method = "rf",
data = training,
trControl = trainControl(method = "cv",
number = 3))
qplot(pred1, pred2, color = wage, data = testing)
qplot(pred1, pred2, color = wage, data = testing)
pred1 <- predict(mod1, testing)
pred2 <- predict(mod2, testing)
qplot(pred1, pred2, color = wage, data = testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
combModFit <- train(wage ~ .,
method = "gam",
data = predDF)
combPred <- predict(combModFit, predDF)
qplot(pred1,pred3)
qplot(pred1, pred2, color = wage, data = testing)
qplot(combPred)
?confusionMatrix
confusionMatrix(combPred,testing$wage)
qplot(testing$wage,combPred)
qplot(testing$wage,pred1)
qplot(testing$wage,combPred)
qplot(testing$wage,pred1)
sqrt(sum((pred1-testing$wage)^2))
RMSE1 <- sqrt(sum((pred1-testing$wage)^2))
RMSE2 <- sqrt(sum((pred2-testing$wage)^2))
RMSEC <- sqrt(sum((combPred-testing$wage)^2))
print(RMSE1,RMSE2,RMSEC)
print(c(RMSE1,RMSE2,RMSEC))
pred1V <- predict(mod1,validation)
pred2V <- predict(mod2,validation)
predVDF <- data.frame(pred1=pred1V,pred2=pred2V)
combPredV <- predict(combModFit,predVDF)
RMSEV1 <- sqrt(sum((pred1V-validation$wage)^2))
RMSEV1 <- sqrt(sum((pred1V-validation$wage)^2))
RMSEV2 <- sqrt(sum((pred2V-validation$wage)^2))
RMSEVC <- sqrt(sum((combPredV-validation$wage)^2))
print(c(RMSEV1,RMSEV2,RMSEVC))
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG",src="google",
from=from.dat, to=to.dat)
head(GOOG)
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG",src="google",
from=from.dat, to=to.dat)
head(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "GOOG")
?quantmod
?getSymbols
getSymbols("GOOG",src="yahoo",from=from.dat, to=to.dat)
head(GOOG)
from.dat <- as.Date("01/01/12", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG",src="google",from=from.dat, to=to.dat)
head(GOOG)
mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
ts1 <- ts(googOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "GOOG")
getSymbols("GE",src="google",from=from.dat, to=to.dat)
head(GE)
from.dat <- as.Date("01/01/12", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GE",src="google",from=from.dat, to=to.dat)
head(GE)
mGE <- to.monthly(GE)
GEOpen <- Op(mGE)
ts1 <- ts(GEOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "GE")
plot(decompose(ts1),xlab="Years+1")
from.dat <- as.Date("01/01/11", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("DAN",src="google",from=from.dat, to=to.dat)
head(DAN)
mDAN <- to.monthly(DAN)
DANOpen <- Op(mDAN)
ts1 <- ts(DANOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "DAN")
plot(decompose(ts1),xlab="Years+1")
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("DAN",src="google",from=from.dat, to=to.dat)
head(DAN)
mDAN <- to.monthly(DAN)
DANOpen <- Op(mDAN)
ts1 <- ts(DANOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "DAN")
#Can decompose into trends,seasonal patterns,cycles
plot(decompose(ts1),xlab="Years+1")
?decompose
plot(decompose(ts1,type="multiplicative"),xlab="Years+1")
plot(decompose(ts1),xlab="Years+1")
plot(st1(ts1),xlab="Years+1")
?st1
library(stats)
plot(st1(ts1),xlab="Years+1")
plot(stl(ts1),xlab="Years+1")
plot(stl(ts1$ts),xlab="Years+1")
class(ts1)
summary(ts1)
class(ts1.ts)
class(ts1$ts)
class(ts1[,1])
plot(stl(as.numeric(ts1)),xlab="Years+1")
ts1 <- st1(DANOpen, frequency = 12)
ts1 <- stl(DANOpen, frequency = 12)
ts1 <- stl(DANOpen)#, frequency = 12)
ts1 <- ts(DANOpen), frequency = 12)
ts1 <- ts(DANOpen, frequency = 12)
ts1 <- ts(DANOpen, frequency = 12)
plot(ts1, xlab = "Years+1", ylab = "DAN")
#Can decompose into trends,seasonal patterns,cycles
plot(decompose(ts1),xlab="Years+1")
ts1Train <- window(ts1,start=1,end=5)
ts1Test <- window(ts1,start=5,end=7-.01)
ts1Train
ts1Test
plot(ts1Train)
lines(ma(ts1Train,order=3),col="red")
lines(ma(ts1Train,order=3),col="red")
library(quantmod); library(forecast)
install.packages("forecast")
library(quantmod); library(forecast)
lines(ma(ts1Train,order=3),col="red")
ets1 <- ets(ts1Train,model="MMM")
fcast <- forecast(ets1)
plot(fcast); lines(ts1Test,col="red")
accuracy(fcast,ts1Test)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y = iris$Species,
p = .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
kMeasn1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
qplot(Petal.Width,Petal.Length,colour=cluster,data=training)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 5)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y = iris$Species,
p = .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y = iris$Species,
p = .7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
kMeans1 <- kmeans(subset(training,
select = -c(Species)),
centers = 3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
modFit <- train(clusters ~ .,
data = subset(training,
select = -c(Species)),
method = "rpart")
table(predict(modFit, training), training$Species)
testClusterPred <- predict(modFit,testing)
table(testClusterPred,testing$Species)
library(ElemStatLearn)
data(vowel.train); data(vowel.test)
library(ElemStatLearn)
data(vowel.train); data(vowel.test)
training <- vowel.train
training <- vowel.train
testing <- vowel.train
testing <- vowel.test
training$y <- as.factor(training$y)
testing$y <- as.factor(testing$y)
rfFit <- train(y ~ .,
method = "rf")
gbmFit <- train(y ~ .,
method = "gbm")
rfFit <- train(y ~ .,
method = "rf",
data = training)
gbmFit <- train(y ~ .,
method = "gbm",
data = training)
?accuracy
predrf <- predict(rfFit,testing)
predgbm <- predict(gbmFit,testing)
length(predrf)
sum(testing$y==predrf)
rfAcc <- sum(testing$y==rfPred)/length(rfPred)
rfPred <- predict(rfFit,testing)
gbmPred <- predict(gbmFit,testing)
rfAcc <- sum(testing$y==rfPred)/length(rfPred)
gbmAcc <- sum(testing$y==gbmPred)/length(gbmPred)
a=4
b=4
c=3
d=4
a==b
a==b==c
(a==b)==c
a==(b&c)
a==(b&&c)
a==(b&d)
a==b&d
a==b&c
(a==b)&(a==d)
(a==b)&(a==c)
CombAcc <- sum((testing$y==gbmPred)&(testing$y==rfPred))/length(testing$y)
CombAcc <- sum((testing$y==gbmPred)&(testing$y==rfPred))/sum(gbmPred==rfPred)
combAcc <- sum((testing$y==gbmPred)&(testing$y==rfPred))/sum(gbmPred==rfPred)
print(c(rfAcc,gbmAcc,combAcc)
print(c(rfAcc,gbmAcc,combAcc))
print(c(rfAcc,gbmAcc,combAcc))
library(caret); library(gbm)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,
p = 3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
set.seed(62433)
rfFit <- train(diagnosis ~ .,
method = "rf",
data = training)
gbmFit <- train(diagnosis ~ .,
method = "gbm",
data = training)
ldaFit <- train(diagnosis ~ .,
method = "lda",
data = training)
rfPred <- predict(rfFit,training)
gbmPred <- predict(gbmFit,training)
ldaPred <- predict(ldaFit,training)
comb <- data.frame(rfPred,
gbmPred,
ldaPred,
diagnosis = training$diagnosis)
combMod <- train(diagnosis ~ .,
method = "rf",
data = comb)
combPred <- predict(combMod,training)
rfAcc <- sum(rfPred==training$diagnosis)/length(rfPred)
gbmAcc <- sum(gbmPred==training$diagnosis)/length(gbmPred)
ldaAcc <- sum(ldaPred==training$diagnosis)/length(ldaPred)
combAcc <- sum(combPred==training$diagnosis)/length(combPred)
print(c("rfAcc",rfAcc,
"gbmAcc",gbmAcc,
"ldaAcc",ldaAcc,
"combAcc",combAcc))
sum(rfPred==training$diagnosis)
head(c(rfPred,gbmPre),30)
head(c(rfPred,gbmPred),30)
levels(rfPred)
sum(rfPred=="Impaired")
sum(rfPred=="Control")
sum(training$diagnosis=="Impaired")
sum(gbmPred=="Control")
rfPred <- predict(rfFit,training)
sum(rfPred==diagnosis)
class(diagnosis)
length(rfPred)
length(diagnosis)
library(caret); library(gbm)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,
p = 3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rfFit <- train(diagnosis ~ .,
method = "rf",
data = training)
gbmFit <- train(diagnosis ~ .,
method = "gbm",
data = training)
ldaFit <- train(diagnosis ~ .,
method = "lda",
data = training)
rfPred <- predict(rfFit,training)
gbmPred <- predict(gbmFit,training)
ldaPred <- predict(ldaFit,training)
comb <- data.frame(rfPred,
gbmPred,
ldaPred,
diagnosis = training$diagnosis)
combMod <- train(diagnosis ~ .,
method = "rf",
data = comb)
combPred <- predict(combMod,training)
rfAcc <- sum(rfPred==training$diagnosis)/length(rfPred)
gbmAcc <- sum(gbmPred==training$diagnosis)/length(gbmPred)
ldaAcc <- sum(ldaPred==training$diagnosis)/length(ldaPred)
combAcc <- sum(combPred==training$diagnosis)/length(combPred)
print(c("rfAcc",rfAcc,
"gbmAcc",gbmAcc,
"ldaAcc",ldaAcc,
"combAcc",combAcc))
confusionMatrix(rfPred,training$diagnosis)
head(training$diagnosis,50)
tail(training$diagnosis,50)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,p = .75)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
head(training)
head(training$diagnosis)
tail(training$diagnosis)
inTrain = createDataPartition(adData$diagnosis,p = .75)
training = adData[inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
data(AlzheimerDisease)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,p = .75)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
training$diagnosis
inTrain = createDataPartition(adData$diagnosis,p = .75, list=FALSE)
training = adData[inTrain,]
testing = adData[-inTrain,]
head(training$diagnosis)
training$diagnosis
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis,p = .75, list=FALSE)
training = adData[inTrain,]
testing = adData[-inTrain,]
training$diagnosis
inTrain
diagnosis
adData$diagnosis
rfPred <- predict(rfFit,testing)
gbmPred <- predict(gbmFit,testing)
ldaPred <- predict(ldaFit,testing)
comb <- data.frame(rfPred,
gbmPred,
ldaPred,
diagnosis = testing$diagnosis)
combMod <- train(diagnosis ~ .,
method = "rf",
data = comb)
combPred <- predict(combMod,testing)
rfAcc <- sum(rfPred==testing$diagnosis)/length(rfPred)
gbmAcc <- sum(gbmPred==testing$diagnosis)/length(gbmPred)
ldaAcc <- sum(ldaPred==testing$diagnosis)/length(ldaPred)
combAcc <- sum(combPred==testing$diagnosis)/length(combPred)
print(c("rfAcc",rfAcc,
"gbmAcc",gbmAcc,
"ldaAcc",ldaAcc,
"combAcc",combAcc))
